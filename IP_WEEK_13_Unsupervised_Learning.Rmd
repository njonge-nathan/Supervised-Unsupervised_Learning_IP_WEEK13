---
title: "Unsupervised_Learning_R"
author: "Nathan_Njonge"
date: "7/8/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## PROBLEM DEFINITION

Kira Plastinina is a Russian brand that is sold through a defunct chain of retail stores in Russia, Ukraine, Kazakhstan, Belarus, China, Philippines, and Armenia. The brand’s Sales and Marketing team would like to understand their customer’s behavior from data that they have collected over the past year. More specifically, they would like to learn the characteristics of customer groups.

## DATA RELEVANCE

> The dataset consists of 10 numerical and 8 categorical attributes. The 'Revenue' attribute can be used as the class label.

> "Administrative", "Administrative Duration", "Informational", "Informational Duration", "Product Related" and "Product Related Duration" represents the number of different types of pages visited by the visitor in that session and total time spent in each of these page categories. The values of these features are derived from the URL information of the pages visited by the user and updated in real-time when a user takes an action, e.g. moving from one page to another.

> The "Bounce Rate", "Exit Rate" and "Page Value" features represent the metrics measured by "Google Analytics" for each page in the e-commerce site. 

> The value of the "Bounce Rate" feature for a web page refers to the percentage of visitors who enter the site from that page and then leave ("bounce") without triggering any other requests to the analytics server during that session. 

> The value of the "Exit Rate" feature for a specific web page is calculated as for all pageviews to the page, the percentage that was the last in the session.

> The "Page Value" feature represents the average value for a web page that a user visited before completing an e-commerce transaction. 

> The "Special Day" feature indicates the closeness of the site visiting time to a specific special day (e.g. Mother’s Day, Valentine's Day) in which the sessions are more likely to be finalized with the transaction. The value of this attribute is determined by considering the dynamics of e-commerce such as the duration between the order date and delivery date. For example, for Valentina’s day, this value takes a nonzero value between February 2 and February 12, zero before and after this date unless it is close to another special day, and its maximum value of 1 on February 8.

> The dataset also includes the operating system, browser, region, traffic type, visitor type as returning or new visitor, a Boolean value indicating whether the date of the visit is weekend, and month of the year.

# load our dataset
```{r}
url <- "http://bit.ly/EcommerceCustomersDataset"
df <- read.csv(url)
head(df)
```

```{r}
# view the bottom of our dataset
tail(df)
```

```{r}
# view the dimensions of our dataset
dim(df)
```
> Our dataset has 18 columns and 12330


```{r}
# view the structure of our dataset
str(df)
```

```{r}
# check for total null values in each column
colSums(is.na(df))
```

```{r}
# fill the missing values in a column with the mean of the column
df$Administrative[is.na(df$Administrative)] <- mean(df$Administrative, na.rm = TRUE)
df$Administrative_Duration[is.na(df$Administrative_Duration)] <- mean(df$Administrative_Duration, na.rm = TRUE)
df$Informational[is.na(df$Informational)] <- mean(df$Informational, na.rm = TRUE)
df$Informational_Duration[is.na(df$Informational_Duration)] <- mean(df$Informational_Duration, na.rm = TRUE)
df$ProductRelated[is.na(df$ProductRelated)] <- mean(df$ProductRelated, na.rm = TRUE)
df$ProductRelated_Duration[is.na(df$ProductRelated_Duration)] <- mean(df$ProductRelated_Duration, na.rm = TRUE)
df$BounceRates[is.na(df$BounceRates)] <- mean(df$BounceRates, na.rm = TRUE)
df$ExitRates[is.na(df$ExitRates)] <- mean(df$ExitRates, na.rm = TRUE)


```

```{r}
# check for any left null values
colSums(is.na(df))
```
```{r}
# find any duplicated rows in our dataset
duplicated_rows <- df[duplicated(df),]
duplicated_rows
```

```{r}
# removing the duplicated rows
unique_df <- unique(df)
unique_df
```



# Handling Outliers

```{r}
# checking for outliers on the Administrative column
boxplot(unique_df$Administrative)
boxplot.stats(unique_df$Administrative)$out
```


```{r}
# checking for outliers in Administrative_Duration
boxplot(unique_df$Administrative_Duration)
boxplot.stats(unique_df$Administrative_Duration)$out
```

```{r}
# check for outliers in Informational
boxplot(unique_df$Informational)
boxplot.stats(unique_df$Informational)$out
```


```{r}
# check for outliers in Informational_Duration
boxplot(unique_df$Informational_Duration)
boxplot.stats(unique_df$Informational_Duration)$out
```

```{r}
# check for outliers in ProductRelated
boxplot(unique_df$ProductRelated)
boxplot.stats(unique_df$ProductRelated)$out
```


```{r}
# check for outliers in ProductRelated_Duration
boxplot(unique_df$ProductRelated_Duration)
boxplot.stats(unique_df$ProductRelated_Duration)$out
```


```{r}
# check for outliers in BounceRates
boxplot(unique_df$BounceRates)
boxplot.stats(unique_df$BounceRates)$out
```


```{r}
# check for outliers in ExitRates
boxplot(unique_df$ExitRates)
boxplot.stats(unique_df$ExitRates)$out
```

```{r}
# check for outliers in PageValues
boxplot(unique_df$PageValues)
boxplot.stats(unique_df$PageValues)$out
```

```{r}
# check for outliers in SpecialDay
boxplot(unique_df$SpecialDay)
boxplot.stats(unique_df$SpecialDay)$out
```


```{r}
# check for outliers in OperatingSystems
boxplot(unique_df$OperatingSystems)
boxplot.stats(unique_df$OperatingSystems)$out
```


```{r}
# check for outliers in Browser
boxplot(unique_df$Browser)
boxplot.stats(unique_df$Browser)$out
```


```{r}
# check for outliers in Region
boxplot(unique_df$Region)
boxplot.stats(unique_df$Region)$out
```

```{r}
# check for outliers in TrafficType
boxplot(unique_df$TrafficType)
boxplot.stats(unique_df$TrafficType)$out
```

# Exploratory Data Analysis
## Univariate Analysis
### 1.Measures of Central Tendency & Measures of Dispersion

```{r}
# mean, median, Min, Max
summary(unique_df)
```


```{r}
# mode function
getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}
```



```{r}
#  mode of numerical columns
library(dplyr)
unique_df %>% summarize_if(is.numeric, getmode)
```


```{r}
# range of numerical columns
unique_df %>% summarize_if(is.numeric, range)
```



```{r}
# Quantile of numerical columns
unique_df %>% summarize_if(is.numeric, quantile)
```

```{r}
# Variance of numerical columns
unique_df %>% summarize_if(is.numeric, var)
```

```{r}
# Standard Deviation of numerical columns
unique_df %>% summarize_if(is.numeric, sd)
```

### Univariate Graphical
### Bar Chart

```{r}
# Bar chart of Month
library(ggplot2)
library(scales)
plotdata <- unique_df %>%
  count(Month) %>%
  mutate(pct = n / sum(n),
         pctlabel = paste0(round(pct*100), "%"))

# plot the bars as percentages, 
# in decending order with bar labels
ggplot(plotdata, 
       aes(x = reorder(Month, -pct),
           y = pct)) + 
  geom_bar(stat = "identity", 
           fill = "indianred3", 
           color = "black") +
  geom_text(aes(label = pctlabel), 
            vjust = -0.25) +
  scale_y_continuous(labels = percent) +
  labs(x = "Month", 
       y = "Percent", 
       title  = "Distribution by Month")
```
> From our barchart of Month distribution we can see that the month of May had the highest distribution at 27% and Feb had the lowest distribution at 1%.

```{r}
# Bar Chart of VisitorType 

plotdata <- unique_df %>%
  count(VisitorType) %>%
  mutate(pct = n / sum(n),
         pctlabel = paste0(round(pct*100), "%"))

# plot the bars as percentages, 
# in decending order with bar labels
ggplot(plotdata, 
       aes(x = reorder(VisitorType, -pct),
           y = pct)) + 
  geom_bar(stat = "identity", 
           fill = "pink", 
           color = "black") +
  geom_text(aes(label = pctlabel), 
            vjust = -0.25) +
  scale_y_continuous(labels = percent) +
  labs(x = "VisitorType", 
       y = "Percent", 
       title  = "Distribution by VisitorType")
```
> From our barchart of visitor type we can see that the Returning Visitor had the highest distribution at 85% ,followed by New_Visitor at 14% and other had the lowest distribution at 1%.


### Piechart
```{r}
# create a pie chart of Weekend
plotdata <- unique_df %>%
  count(Weekend) %>%
  arrange(desc(Weekend)) %>%
  mutate(prop = round(n*100/sum(n), 1),
         lab.ypos = cumsum(prop) - 0.5*prop)

plotdata$label <- paste0(plotdata$Weekend, "\n",
                         round(plotdata$prop), "%")

ggplot(plotdata, 
       aes(x = "", 
           y = prop, 
           fill = Weekend)) +
  geom_bar(width = 1, 
           stat = "identity", 
           color = "black") +
  geom_text(aes(y = lab.ypos, label = label), 
            color = "black") +
  coord_polar("y", 
              start = 0, 
              direction = -1) +
  theme_void() +
  theme(legend.position = "FALSE") +
  labs(title = "Participants by Weekend")
```
> From our piechart of Weekend the boolean False had the higest distribution at 77%

```{r}
# create a pie chart of Revenue
plotdata <- unique_df %>%
  count(Revenue) %>%
  arrange(desc(Revenue)) %>%
  mutate(prop = round(n*100/sum(n), 1),
         lab.ypos = cumsum(prop) - 0.5*prop)

plotdata$label <- paste0(plotdata$Revenue, "\n",
                         round(plotdata$prop), "%")

ggplot(plotdata, 
       aes(x = "", 
           y = prop, 
           fill = Revenue)) +
  geom_bar(width = 1, 
           stat = "identity", 
           color = "black") +
  geom_text(aes(y = lab.ypos, label = label), 
            color = "black") +
  coord_polar("y", 
              start = 0, 
              direction = -1) +
  theme_void() +
  theme(legend.position = "FALSE") +
  labs(title = "Participants by Revenue")
```
> From our piechart of Revenue the boolean False had the highest distribution at 84%.

### Histogram

```{r}
# Histogram of Administrative
ggplot(unique_df, aes(x = Administrative)) +
  geom_histogram(fill = "purple", 
                 color = "white",
                 bins = 20) + 
  labs(title="Participants by Administrative",
       x = " Administrative")
```
> Histogram of Administrative

```{r}
# Histogram of Administrative_Duration
ggplot(unique_df, aes(x = Administrative_Duration)) +
  geom_histogram(fill = "violet", 
                 color = "white",
                 bins = 30) + 
  labs(title="Distribution by Administrative_Duration",
       x = " Administrative_Duration")
```
> Histogram of Administrative_Duration

```{r}
# Histogram of Informational
ggplot(unique_df, aes(x = Informational)) +
  geom_histogram(fill = "orange", 
                 color = "white",
                 bins = 30) + 
  labs(title="Distribution by Informational",
       x = " Informational")
```
> Histogram of Informational 

```{r}
# Histogram of Informational_Duration
ggplot(unique_df, aes(x = Informational_Duration)) +
  geom_histogram(fill = "purple", 
                 color = "white",
                 bins = 20) + 
  labs(title="Informational_Duration",
       x = " Informational_Duration")
```
> Histogram of Informational_Duration

```{r}
# Histogram of ProductRelated
ggplot(unique_df, aes(x = ProductRelated)) +
  geom_histogram(fill = "maroon", 
                 color = "white",
                 bins = 20) + 
  labs(title="ProductRelated",
       x = "ProductRelated")
```
>Histogram of Product Related Distribution

```{r}
# Histogram of ProductRelated_Duration
ggplot(unique_df, aes(x = ProductRelated_Duration)) +
  geom_histogram(fill = "red", 
                 color = "white",
                 bins = 30) + 
  labs(title="ProductRelated_Duration",
       x = "ProductRelated_Duration")
```
> Histogram of Product Related Duration distribution.

```{r}
# Histogram of BounceRates
ggplot(unique_df, aes(x = BounceRates)) +
  geom_histogram(fill = "blue", 
                 color = "white",
                 bins = 30) + 
  labs(title="BounceRates",
       x = "BounceRates")
```

> Histogram of Bounce Rates distribution

```{r}
# Histogram of ExitRates
ggplot(unique_df, aes(x = ExitRates)) +
  geom_histogram(fill = "green", 
                 color = "white",
                 bins = 30) + 
  labs(title="ExitRates",
       x = "ExitRates")
```
> Histogram of Exit Rates distribution.

```{r}
# Histogram of PageValues
ggplot(unique_df, aes(x = PageValues)) +
  geom_histogram(fill = "orange", 
                 color = "white",
                 bins = 20) + 
  labs(title="Histogram of PageValues",
       x = "PageValues")
```
> Histogram of Page values distribution.

#### Density Plot
```{r}

# Create a kernel density plot of SpecialDay
ggplot(unique_df, aes(x = SpecialDay)) +
  geom_density(fill = "purple") + 
  labs(title = "Density plot of SpecialDay")
```
>Histogram of Special Day distribution,

```{r}
# Create a kernel density plot of OperatingSystems
ggplot(unique_df, aes(x = OperatingSystems)) +
  geom_density(fill = "black") + 
  labs(title = "Density plot of OperatingSystems")
```
> Density plot of operating systems distribution

```{r}
# Create a kernel density plot of Browser
ggplot(unique_df, aes(x = Browser)) +
  geom_density(fill = "indianred3") + 
  labs(title = "Density plot of Browser")
```
> Density Plot of Browser distribution

```{r}
# Density plot of Region
ggplot(unique_df, aes(x = Region)) +
  geom_density(fill = "deepskyblue") +
  labs(title = "Density plot of Region")
```

> Density plot of Region distribution

```{r}
# Density plot of TrafficType
ggplot(unique_df, aes(x = TrafficType)) +
  geom_density(fill = "purple") +
  labs(title = "Density plot of TrafficType")
```
> Density plot of Traffic Type distribution.

#### Bivariate Analysis

##### Grouped Bar Chart
```{r}
# grouped bar chart of Month vs Visitor Type
ggplot(unique_df, 
       aes(x = Month, 
           fill = VisitorType)) + 
  geom_bar(position = position_dodge(preserve = "single")) +
  labs(title = "Grouped bar chart of Month vs Visitor Type")
```
> From our grouped Bar Chart we can see that Returning vistor had the highest distribution in each month.

```{r}
# Grouped bar chart of Visitor Type vs Weekend
ggplot(unique_df, 
       aes(x = VisitorType, 
           fill = Weekend)) + 
  geom_bar(position = position_dodge(preserve = "single")) +
  labs(title = "Grouped bar chart of Visitor Type vs Weekend")
```
> From our visualization we can see that we had more visitors on weekdays compared to the weekends.

### Scatterplot

```{r}
# scatterplot of Administrative vs Administrative Duration with linear fit line
ggplot(unique_df,
       aes(x = Administrative, 
           y = Administrative_Duration)) +
  geom_point(color= "steelblue") +
  geom_smooth(method = "lm",
              formula = y ~ x,
              color = "indianred3") +
  labs(title = "Scatterplot of Administrative vs Administrative Duration with linear fit line")
```
> From our visualization administrative duration increases with the number of Administrative pages visited by the visitor.

```{r}
# scatterplot of Informational vs Informational_Duration with linear fit line
ggplot(unique_df,
       aes(x = Informational, 
           y = Informational_Duration)) +
  geom_point(color= "black") +
  geom_smooth(method = "lm",
              formula = y ~ x,
              color = "indianred3") +
  labs(title = "Scatterplot of Informational vs Informational_Duration with linear fit line")
```

> From our visualization Informational_Duration increases with the number of Informational pages visited by the visitor.

```{r}
# scatterplot of ProductRelated vs ProductRelated_Duration with linear fit line
ggplot(unique_df,
       aes(x = ProductRelated, 
           y = ProductRelated_Duration)) +
  geom_point(color= "purple") +
  geom_smooth(method = "lm",
              formula = y ~ x,
              color = "indianred3") +
  labs(title = "Scatterplot of ProductRelated vs ProductRelated_Duration with linear fit line")
```
> From our visualization ProductRelated_Duration increases with the number of ProductRelated pages visited by the visitor.

### Bar chart

```{r}
# calculate the mean PageValues for each visitor type
plotdata <- unique_df %>%
  group_by(VisitorType) %>%
  summarize(mean_page_values = mean(PageValues))

# plot mean salaries
ggplot(plotdata, 
       aes(x = VisitorType, 
           y = mean_page_values)) +
  geom_bar(stat = "identity",
           fill = "darkblue")+
   labs(title = "Mean PageValues for each visitor type")
```
> From our visualization the mean page value for other visitor type was higher compared to the rest of the visitor types

```{r}
# calculate the mean TrafficType for each Month
plotdata <- unique_df %>%
  group_by(Month) %>%
  summarize(mean_traffic_type = mean(TrafficType))

# plot mean salaries
ggplot(plotdata, 
       aes(x = Month, 
           y = mean_traffic_type)) +
  geom_bar(stat = "identity",
           fill = "orange") +
  labs(title = "Mean TrafficType for each Month")
```
> From our barchart the Months of May ,November and October had among the highest traffic types.

#### Strip plots

```{r}
# distribution of bounce rates by visitor type
ggplot(unique_df, 
       aes(y = VisitorType, 
           x = BounceRates,
           color = VisitorType )) +
  geom_jitter() + 
  labs(title = "BounceRates distribution by VisitorType")
```
> From our visualization the Returning_Visitor had a higher bounce rates followed by the New_visitor.

```{r}
# distribution of ExitRates distribution by VisitorType
ggplot(unique_df, 
       aes(y = VisitorType, 
           x = ExitRates,
           color = VisitorType)) +
  geom_jitter() + 
  labs(title = "ExitRates distribution by VisitorType")
```
> From our visualization the Returning visitor had a higher exit rates.

#### Multivariate

```{r}
# plot TrafficType histograms by VisitorType
ggplot(unique_df, aes(x = TrafficType)) +
  geom_histogram(fill = "red",
                 color = "white",
                 bins = 30) +
  facet_wrap(~VisitorType, ncol = 1) +
  labs(title = "TrafficType histograms by VisitorType")
```
> From  our visualization the Returning Visitor had the highest traffic type count.

```{r}
ggplot(unique_df, 
       aes(x = Month, 
           y = TrafficType, 
           color = VisitorType, 
           shape = Weekend)) +
  geom_point(size = 3, 
             alpha = .6) +
  labs(title = "Traffic Type by Visitor Type, Weekend, and Month")
```
> From our visualization the month of May , November and October had among the highest traffic type mostly from the Returning visitors during the weekends.

### Solution Implementation

# Preprocessing the dataset 

```{r}
df.new <- unique_df[, c(1,2,3,4,5,6,7,8,9,10,12,13,14,15)]
df.class <- unique_df[, "Revenue"]
head(df.new)
```

```{r}
# view the class column
head(df.class)
```

```{r}
# normalize the dataset
normalize <- function(x){
  return ((x-min(x)) / (max(x)-min(x)))
}
df.new$Administrative<- normalize(df.new$Administrative)
df.new$Administrative_Duration<- normalize(df.new$Administrative_Duration)
df.new$Informational<- normalize(df.new$Informational)
df.new$Informational_Duration<- normalize(df.new$Informational_Duration)
df.new$ProductRelated<- normalize(df.new$ProductRelated)
df.new$ProductRelated_Duration<- normalize(df.new$ProductRelated_Duration)
df.new$BounceRates<- normalize(df.new$BounceRates)
df.new$ExitRates<- normalize(df.new$ExitRates)
df.new$PageValues<- normalize(df.new$PageValues)
df.new$SpecialDay<- normalize(df.new$SpecialDay)
df.new$OperatingSystems<- normalize(df.new$OperatingSystems)
df.new$Browser<- normalize(df.new$Browser)
df.new$Region<- normalize(df.new$Region)
df.new$TrafficType<- normalize(df.new$TrafficType)
head(df.new)
```


```{r}
# applying the kMeans clustering algorithm
# no. of centroids(k)=2

set.seed(1234)
result<- kmeans(df.new, centers = 2, nstart = 25) 


# Previewing the no. of records in each cluster
 
result$size 
```


```{r}
# Getting the value of cluster center datapoint value(2 centers for k=2)

result$centers
```

```{r}
# Getting the cluster vector that shows the cluster where each record falls

result$cluster
```





```{r}

table(result$cluster, df.class)
```
```{r}
library(factoextra)
fviz_cluster(result, data = df.new)
```

# Examine the difference in results with different values of k
```{r}
k3 <- kmeans(df.new, centers = 3, nstart = 25)
k4 <- kmeans(df.new, centers = 4, nstart = 25)
k5 <- kmeans(df.new, centers = 5, nstart = 25)

# plots to compare
library(factoextra)
p1 <- fviz_cluster(result, geom = "point", data = df.new) + ggtitle("k = 2")
p2 <- fviz_cluster(k3, geom = "point",  data = df.new) + ggtitle("k = 3")
p3 <- fviz_cluster(k4, geom = "point",  data = df.new) + ggtitle("k = 4")
p4 <- fviz_cluster(k5, geom = "point",  data = df.new) + ggtitle("k = 5")

library(gridExtra)
grid.arrange(p1, p2, p3, p4, nrow = 2)
```
# Determining Optimal Clusters

## Elbow Method
```{r}
devtools::install_github("tidyverse/purrr")
library(purrr)
set.seed(123)

# function to compute total within-cluster sum of square 
wss <- function(k) {
  kmeans(df.new, k, nstart = 10 )$tot.withinss
}

# Compute and plot wss for k = 1 to k = 15
k.values <- 1:15

# extract wss for 2-15 clusters
wss_values <- map_dbl(k.values, wss)

plot(k.values, wss_values,
       type="b", pch = 19, frame = FALSE, 
       xlab="Number of clusters K",
       ylab="Total within-clusters sum of squares")
```


```{r}
library(factoextra)
#library(NbClust)
set.seed(123)

fviz_nbclust(df.new, kmeans, method = "wss")
```

# Average Silhouette Method

```{r}
library (cluster)
# function to compute average silhouette for k clusters
avg_sil <- function(k) {
  km.res <- kmeans(df.new, centers = k, nstart = 25)
  ss <- silhouette(km.res$cluster, dist(df.new))
  mean(ss[, 3])
}

# Compute and plot ss for k = 1 to k = 15
k.values <- 2:15

# extract avg silhouette for 2-15 clusters
avg_sil_values <- map_dbl(k.values, avg_sil)

plot(k.values, avg_sil_values,
       type = "b", pch = 19, frame = FALSE, 
       xlab = "Number of clusters K",
       ylab = "Average Silhouettes")
```
```{r}
fviz_nbclust(df.new, kmeans, method = "silhouette")
```
> From our average silhoutte method we can identify our optimal number of clusters to be 3.

# Extracting Results

```{r}
# Compute k-means clustering with k = 3
set.seed(123)
final <- kmeans(df.new, 3, nstart = 25)
print(final)
```

# Visualizing our results

```{r}
fviz_cluster(final, data = df.new)
```




# Challenging the Solution
## Hierachical Clustering

```{r}
# Standardizing the data
df.new <- scale(df.new)
head(df.new)
```

## Agglomerative Hierachical Clustering
```{r}
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms


# Dissimilarity matrix
d <- dist(df.new, method = "euclidean")

# Hierarchical clustering using Complete Linkage
hc1 <- hclust(d, method = "complete" )

# Plot the obtained dendrogram
plot(hc1, cex = 0.6, hang = -1, labels = FALSE)
```




## DBSCAN Clustering
```{r}
# minimum 4 points with in a distance of eps(0.4)
library("dbscan")
db<-dbscan(df.new,eps=0.4,minPts = 4)

# print the clustering results
print(db)
```
```{r}
# plot our clusters 

hullplot(df.new,db$cluster)
```
### Conclusion

From our analysis we deduced the ideal optimal number of clusters using hierachical clustering to be 3